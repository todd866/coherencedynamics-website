---
slug: the-philosophy-trilogy
title: The Philosophy Trilogy
subtitle: Agency, frustration, and costly signaling from bacteria to belief systems
date: 2025-12-29
tags:
  - philosophy
  - agency
  - epistemology
  - signaling
  - dimensionality
summary: Three papers, one question. How do systems coordinate when participants can't verify each other's internal states? The answer connects bacterial quorum sensing to human ideology, and explains why mature institutions resist evidence.
relatedPapers:
  - agency-power
  - epistemic-frustration
  - costly-signaling
---

I've been working on a trilogy of papers for *Biology & Philosophy* that tackle a single question from three angles: **How do systems coordinate when participants can't verify each other's internal states?**

This sounds abstract, but it's deeply practical. Cells can't read each other's genomes. Organisms can't read each other's intentions. Institutions can't read each other's strategic calculations. Yet coordination happens---somehow. These papers explore the mechanisms.

---

## Paper 1: Agency and Power

The first paper ([Agency and Power](/papers/agency-power)) asks: what *is* an agent, and how do agents control each other?

The standard philosophical move is to draw a bright line: agents have beliefs and desires, non-agents don't. But this creates awkward categories. Is a bacterium responding to chemical gradients an agent? A thermostat? A corporation?

I propose a graded framework instead. A system is an agent *to the extent* that it:

1. Maintains internal states representing self and environment
2. Uses those states to select among alternative actions
3. Has those states be *causally efficacious*---they actually guide behavior, not just correlate with it

This gives us a spectrum. A thermostat has minimal agency (one internal state, one action dimension). A bacterium has more (chemotaxis involves gradient sensing, memory, and behavioral switching). A human has much more. A corporation is a weird case---it presents an agent-like interface to the world but outsources its actual cognition to constituent minds. I call these **demi-agents**.

Once you have agents, you can ask about power. Power is **control of controllers**---the capacity to reliably steer another agent's action by manipulating the variables that govern its action selection.

Power operates through two routes:

1. **Representation-mediated:** manipulating what the target perceives or values
2. **Constraint/controller-hijack:** limiting available actions or directly modifying control systems

Both routes appear at every biological scale. Parasites hijack host nervous systems (constraint). Prestige hierarchies shape what people want to want (representation-mediated). Quorum sensing bacteria secrete signals that alter each other's gene expression (both).

The key insight: **the same mechanisms trace continuously from bacteria to human institutions.** This isn't metaphor. It's structural homology---convergent solutions to the control-of-controllers problem.

---

## Paper 2: Epistemic Frustration

The second paper ([Epistemic Frustration](/papers/epistemic-frustration)) asks: why do mature institutions resist evidence?

The usual answer is bias, groupthink, or motivated reasoning. But I think there's something deeper going on.

Consider a high-dimensional optimization problem---say, coordinating a complex organization. Many configurations might be locally optimal. Now project this into a low-dimensional space---say, the discourse available to participants. What happens?

Multiple high-dimensional optima can **project to the same low-dimensional position**. Conversely, a single high-dimensional optimum can **appear contradictory** when viewed from different low-dimensional angles.

This creates **epistemic frustration**---disagreement that is *geometric*, not epistemic. Two observers seeing different constraints can each be locally correct but globally incompatible. They're not irrational. They're projecting different faces of a shared high-dimensional reality into incompatible low-dimensional frames.

As coordination stakes increase, systems undergo a predictable transition:

- **Epistemic-first regime:** truth-seeking dominates; anomalies trigger model revision
- **Coordination-first regime:** stability-seeking dominates; anomalies are absorbed or moralized away

This isn't irrationality. It's optimization under a different objective function. When the cost of coordination failure exceeds the cost of local inaccuracy, systems *should* prioritize coherence over truth.

The paper provides a quantitative diagnostic: systems become effectively unfalsifiable when the degrees of freedom in their error-models exceed their informational constraints. At that point, any evidence can be absorbed without revision.

This explains phenomena like:

- **Moralization of dissent:** disagreement becomes defection, not just error
- **Sacred value formation:** certain propositions become off-limits to cost-benefit analysis
- **Paradigm entrenchment:** anomalies accumulate indefinitely rather than triggering shifts

These aren't bugs. They're features of coordination-first systems operating under epistemic frustration.

---

## Paper 3: Costly Signaling

The third paper ([Costly Signaling](/papers/costly-signaling)) asks: how do coalitions form when members can't verify each other's commitment?

The answer is **costly signaling**---signals that are too expensive to fake. If defection pays $D$ and the signal costs $C$, then a reliable signal requires $C > D$. Only those who genuinely expect to benefit from long-term coalition membership will pay the cost.

This is economics 101. What's less obvious is the *phenomenology* of costly signals in practice.

As coordination stakes increase, signals become increasingly **individually dominated**---they appear irrational from the individual's perspective. Ritual mutilation, dietary restrictions, celibacy vows, public confession of improbable beliefs. These aren't bugs. They're the point. A signal that looks rational provides no information about commitment.

The paper identifies a structural cluster that appears wherever high-stakes coalition formation occurs:

1. **Ritual:** costly, arbitrary, synchronized behavior
2. **Sacred markers:** propositions held immune to evidence
3. **Deviation punishment:** harsher penalties for internal defection than external opposition
4. **Identity fusion:** self-concept merging with group identity
5. **Evidence resistance:** counter-evidence *strengthening* commitment

These aren't independent phenomena. They're components of a single mechanism---commitment verification under information asymmetry.

The key insight about evidence resistance: **counter-evidence raises signal cost**. If you maintain a belief despite strong evidence against it, you're paying a higher epistemic cost---and that makes your commitment signal more reliable. This is why attacking someone's sacred beliefs often strengthens them. You're not refuting their epistemics. You're *validating their signaling*.

The paper traces this cluster from bacterial quorum sensing (costly autoinducers), through insect colony recognition (hydrocarbon profiles), to human ideological movements (all of the above). The mechanisms are homologous---convergent solutions to the commitment verification problem.

---

## The Unified Picture

Together, these papers offer a framework for understanding cross-scale coordination:

1. **Agency is graded.** Systems exhibit agent-like behavior to varying degrees. Power is control of controllers, operating through representation or constraint.

2. **Coordination induces epistemic frustration.** High-dimensional realities projected into low-dimensional discourse create geometric disagreements that look like epistemic failures but aren't.

3. **Commitment requires costly signals.** Coalitions form around behaviors that are too expensive to fake, generating a predictable cluster of ritual, sacred markers, and evidence resistance.

These aren't independent claims. They're connected:

- Power operates by manipulating agents' internal models (Paper 1). But those models are low-dimensional projections of high-dimensional realities (Paper 2). So power is partly about *controlling which projection* agents occupy.

- Epistemic frustration creates coordination-first systems (Paper 2). But coordination-first systems need commitment verification (Paper 3). So the shift from truth-seeking to stability-seeking *predicts* the emergence of costly signaling clusters.

- Costly signals work by being individually dominated (Paper 3). But what counts as "dominated" depends on the agent's internal model (Paper 1). So signaling regimes and agency interact---the signal shapes what kind of agent you become.

The papers are distinct but mutually reinforcing. Each addresses a different facet of the same underlying problem: how do systems coordinate when internal states are private?

---

## Why Philosophy?

Why submit these to *Biology & Philosophy* rather than biology journals?

Because the claims are conceptual, not empirical. I'm not reporting new data. I'm proposing a framework that *organizes* existing data from multiple domains---microbiology, ethology, anthropology, organizational theory---into a coherent picture.

That's a philosophical contribution. It's also the kind of contribution that domain journals tend to reject ("outside our scope," "too theoretical"). Philosophy of biology is the natural home.

There's also a meta-level irony. Paper 2 predicts that mature institutions will resist framework-level challenges and moralize dissent. If these papers get rejected with vague "not a good fit" responses, that's... consistent with the theory.

---

## What Would Prove Me Wrong?

Each paper has specific predictions:

**Agency and Power:**
- If power mechanisms differ qualitatively across scales (not just quantitatively), the cross-scale continuity claim fails
- If demi-agents turn out to have genuine unified agency (not outsourced cognition), the framework needs revision

**Epistemic Frustration:**
- If we find coordination-first systems that maintain epistemic openness, the transition isn't as deterministic as claimed
- If epistemic frustration can be resolved by better discourse design, the dimensional argument is wrong

**Costly Signaling:**
- If we find stable coalitions without costly signals, the mechanism isn't necessary
- If the structural cluster (ritual, sacred markers, etc.) fails to appear in predicted contexts, the homology claim fails

These are real risks. The framework could be wrong. But if it's right, it offers a principled way to understand why institutions behave the way they do---and why simple interventions (better arguments, more evidence, clearer communication) often fail.

---

*The three papers are: [Agency and Power](/papers/agency-power) (submitted), [Epistemic Frustration](/papers/epistemic-frustration) (in preparation), and [Costly Signaling](/papers/costly-signaling) (in preparation). All are targeted at Biology & Philosophy.*
